{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating, Saving and Loading Checkpoints for RL training loops\n",
    " This notebook is about checkpoints for reinforcement learning training loops. It is designed for using pytorch networks. This notebook is intended as help for creating loops creating, saving and loading checkpoints and does not include full code of networks or RL training loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "from dotmap import DotMap\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">First define parameters about the location to save checkpoints as well as the frequency they should be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define name of folder to save checkpoints, checkpoint frequency and path to save checkpoints\n",
    "EXPERIMENT_NAME = 'lunarlander-goestomars'\n",
    "CHECKPOINT_FREQUENCY = 10\n",
    "ROOT_DIR = 'C:/Users/name/Documents/folder'\n",
    "BASE_CHECKPOINT_PATH = f\"{ROOT_DIR}/checkpoints/{EXPERIMENT_NAME}/\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">These checkpoints should include the hyperparameters, which are defined here in the following way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some parameters that are used in training, and saved every checkpoint\n",
    "class HyperParameters():\n",
    "    scale_reward:         float = SCALE_REWARD\n",
    "    min_reward:           float = MIN_REWARD\n",
    "    batch_size:           int   = BATCH_SIZE\n",
    "    discount:             float = DISCOUNT\n",
    "    gae_lambda:           float = GAE_LAMBDA\n",
    "    ppo_clip:             float = PPO_CLIP\n",
    "    ppo_epochs:           int   = PPO_EPOCHS\n",
    "    max_grad_norm:        float = MAX_GRAD_NORM\n",
    "    entropy_factor:       float = ENTROPY_FACTOR\n",
    "    actor_learning_rate:  float = ACTOR_LEARNING_RATE\n",
    "    critic_learning_rate: float = CRITIC_LEARNING_RATE\n",
    "    rollout_steps:        int = ROLLOUT_STEPS\n",
    "    parallel_rollouts:    int = PARALLEL_ROLLOUTS\n",
    "        \n",
    "hp = HyperParameters(parallel_rollouts=32, rollout_steps=2000, batch_size=600)\n",
    "batch_count = hp.parallel_rollouts * hp.rollout_steps / hp.recurrent_seq_len / hp.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Next are the functions to save and load the checkpoints.\n",
    "\n",
    "- save_checkpoint() creates the files that are going to be saved using dotmap. It saves the environment, iteration, hyperparameters and actor and critic networks including optimizers. More things can be added here such as termination conditions that are used to stop training early\n",
    "\n",
    "- load_checkpoint() loads the created checkpoints to continue training from the latest checkpoint.\n",
    "\n",
    "- load_trained_model() loads only actor and critic to use them for testing or evaluation.\n",
    "\n",
    "- get_last_checkpoint_iteration() is used to continue counting from the latest checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(actor, critic, actor_optimizer, critic_optimizer, iteration, stop_conditions):\n",
    "    print(\"Saving Checkpoint\")\n",
    "    #Save training checkpoint.\n",
    "    checkpoint = DotMap()\n",
    "    checkpoint.env = ENV\n",
    "    checkpoint.iteration = iteration\n",
    "    checkpoint.hp = hp\n",
    "    CHECKPOINT_PATH = BASE_CHECKPOINT_PATH + f\"{iteration}/\"\n",
    "    pathlib.Path(CHECKPOINT_PATH).mkdir(parents=True, exist_ok=True) \n",
    "    with open(CHECKPOINT_PATH + \"parameters.pt\", \"wb\") as f:\n",
    "        pickle.dump(checkpoint, f)\n",
    "    with open(CHECKPOINT_PATH + \"actor_class.pt\", \"wb\") as f:\n",
    "        pickle.dump(Actor, f)\n",
    "    with open(CHECKPOINT_PATH + \"critic_class.pt\", \"wb\") as f:\n",
    "        pickle.dump(Critic, f)\n",
    "    torch.save(actor.state_dict(), CHECKPOINT_PATH + \"actor.pt\")\n",
    "    torch.save(critic.state_dict(), CHECKPOINT_PATH + \"critic.pt\")\n",
    "    torch.save(actor_optimizer.state_dict(), CHECKPOINT_PATH + \"actor_optimizer.pt\")\n",
    "    torch.save(critic_optimizer.state_dict(), CHECKPOINT_PATH + \"critic_optimizer.pt\")\n",
    "    \n",
    "def load_checkpoint(iteration):\n",
    "    print(\"Loading Checkpoint\")\n",
    "    #Load from training checkpoint.\n",
    "    CHECKPOINT_PATH = BASE_CHECKPOINT_PATH + f\"{iteration}/\"\n",
    "    with open(CHECKPOINT_PATH + \"parameters.pt\", \"rb\") as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "        \n",
    "    assert ENV == checkpoint.env, \"To resume training environment must match current settings.\"\n",
    "    assert hp == checkpoint.hp, \"To resume training hyperparameters must match current settings.\"\n",
    "\n",
    "    actor_state_dict = torch.load(CHECKPOINT_PATH + \"actor.pt\", map_location=torch.device(DEVICE))\n",
    "    critic_state_dict = torch.load(CHECKPOINT_PATH + \"critic.pt\", map_location=torch.device(DEVICE))\n",
    "    actor_optimizer_state_dict = torch.load(CHECKPOINT_PATH + \"actor_optimizer.pt\", map_location=torch.device(DEVICE))\n",
    "    critic_optimizer_state_dict = torch.load(CHECKPOINT_PATH + \"critic_optimizer.pt\", map_location=torch.device(DEVICE))\n",
    "    \n",
    "    return (actor_state_dict, critic_state_dict,\n",
    "           actor_optimizer_state_dict, critic_optimizer_state_dict,\n",
    "           checkpoint.stop_conditions)\n",
    "\n",
    "def load_trained_model(iteration):\n",
    "    #Load previously trained model based on the number of training iterations, to use for testing for example\n",
    "    print(\"Loading Trained Model\")\n",
    "    obsv_dim, action_dim, continuous_action_space = get_env_space()\n",
    "    # actor and critic are pytorch NNs\n",
    "    actor = Actor(obsv_dim,\n",
    "                  action_dim,\n",
    "                  continuous_action_space=continuous_action_space,\n",
    "                  trainable_std_dev=hp.trainable_std_dev,\n",
    "                  init_log_std_dev=hp.init_log_std_dev)\n",
    "    critic = Critic(obsv_dim)\n",
    "    \n",
    "    #Load from training checkpoint.\n",
    "    CHECKPOINT_PATH = BASE_CHECKPOINT_PATH + f\"{iteration}/\"\n",
    "    with open(CHECKPOINT_PATH + \"parameters.pt\", \"rb\") as f:\n",
    "        checkpoint = pickle.load(f)\n",
    "        \n",
    "    actor_state_dict = torch.load(CHECKPOINT_PATH + \"actor.pt\", map_location=torch.device(DEVICE))\n",
    "    critic_state_dict = torch.load(CHECKPOINT_PATH + \"critic.pt\", map_location=torch.device(DEVICE))\n",
    "    \n",
    "    actor.load_state_dict(actor_state_dict, strict=True) \n",
    "    critic.load_state_dict(critic_state_dict, strict=True)\n",
    "    \n",
    "    return actor, critic\n",
    "\n",
    "def get_last_checkpoint_iteration():\n",
    "    # needed to load from existing checkpoints and continue onwards\n",
    "    # checks if checkpoint exists\n",
    "    if os.path.isdir(BASE_CHECKPOINT_PATH):\n",
    "        max_checkpoint_iteration = max([int(dirname) for dirname in os.listdir(BASE_CHECKPOINT_PATH)])\n",
    "    else:\n",
    "        max_checkpoint_iteration = 0\n",
    "    return max_checkpoint_iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Start() initializes the actor and critic networks and loads from checkpoints of they exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    # initialization of NNs and checkpoints\n",
    "    max_checkpoint_iteration = get_last_checkpoint_iteration()\n",
    "    \n",
    "    obsv_dim, action_dim, continuous_action_space = get_env_space()\n",
    "    # actor and critic are pytorch NNs here\n",
    "    actor = Actor(obsv_dim,\n",
    "                  action_dim,\n",
    "                  continuous_action_space=continuous_action_space,\n",
    "                  trainable_std_dev=hp.trainable_std_dev,\n",
    "                  init_log_std_dev=hp.init_log_std_dev)\n",
    "    critic = Critic(obsv_dim)\n",
    "        \n",
    "    actor_optimizer = optim.AdamW(actor.parameters(), lr=hp.actor_learning_rate)\n",
    "    critic_optimizer = optim.AdamW(critic.parameters(), lr=hp.critic_learning_rate)\n",
    "    \n",
    "        \n",
    "    # check if checkpoint exists, then load it\n",
    "    if max_checkpoint_iteration > 0:\n",
    "        actor_state_dict, critic_state_dict, actor_optimizer_state_dict, critic_optimizer_state_dict, stop_conditions = load_checkpoint(max_checkpoint_iteration)\n",
    "        \n",
    "        actor.load_state_dict(actor_state_dict, strict=True) \n",
    "        critic.load_state_dict(critic_state_dict, strict=True)\n",
    "        actor_optimizer.load_state_dict(actor_optimizer_state_dict)\n",
    "        critic_optimizer.load_state_dict(critic_optimizer_state_dict)\n",
    "\n",
    "        # move optimizers\n",
    "        for state in actor_optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(DEVICE)\n",
    "\n",
    "        for state in critic_optimizer.state.values():\n",
    "            for k, v in state.items():\n",
    "                if isinstance(v, torch.Tensor):\n",
    "                    state[k] = v.to(DEVICE)\n",
    "                    \n",
    "    return actor, critic, actor_optimizer, critic_optimizer, max_checkpoint_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In order to use these functions, save_checkpoint() should be called inside the training loop. CHECKPOINT_FREQUENCY makes sure that checkpoints are saved according to the specified frequency. Iteration should be included as a variable to provide names accordingly to the folders of checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this to your training loop to make and save checkpoints    \n",
    "if iteration % CHECKPOINT_FREQUENCY == 0: \n",
    "    save_checkpoint(actor,critic, actor_optimizer, critic_optimizer, iteration, stop_conditions)\n",
    "iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">After training, training can be conitued using the saved checkpoint or a trained pair of actor and critic can be loaded. The following code provides an example use of loading actor and critic from the multiple checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained actor and critic\n",
    "models = [x for x in range(0, 300, 10)]\n",
    "for model in models:\n",
    "    actor, critic = load_trained_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
