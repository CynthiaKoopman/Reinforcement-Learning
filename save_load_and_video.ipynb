{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & load Pytorch networks and Create Video using learned Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for saving and loading pytorch network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add these to your Actor-Critic class\n",
    "\n",
    "def save(self, directory1, directory2):\n",
    "    torch.save(self.pi.state_dict(), directory1)\n",
    "    torch.save(self.v.state_dict(), directory2)\n",
    "\n",
    "def load(self, directory1, directory2):\n",
    "    self.pi.load_state_dict(torch.load(directory1))\n",
    "    self.v.load_state_dict(torch.load(directory2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage of the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the policy you start with (you can also load the one you ended with in previous runs)\n",
    "directory1 = \"./LunarLanderContinuous-v2_first_actor.pth\"\n",
    "directory2 = \"./LunarLanderContinuous-v2_first_critic.pth\"\n",
    "ac.save(directory1, directory2)\n",
    "\n",
    "    #perform reinforcement learning loop\n",
    "\n",
    "# save the policy you end with\n",
    "directory1 = \"./LunarLanderContinuous-v2_final_actor.pth\"\n",
    "directory2 = \"./LunarLanderContinuous-v2_final_critic.pth\"\n",
    "ac.save(directory1, directory2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create video from previous learned policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test environment\n",
    "test_env = gym.make(\"LunarLanderContinuous-v2\")\n",
    "\n",
    "# load previous policy\n",
    "# use your own actor-critic network\n",
    "net = MLPActorCritic(test_env.observation_space, test_env.action_space, hidden_sizes=(32,32), activation=nn.ReLU)\n",
    "directory1 = \"./LunarLanderContinuous-v2_first_actor.pth\"\n",
    "directory2 = \"./LunarLanderContinuous-v2_first_critic.pth\"\n",
    "net.load(directory1, directory2)\n",
    "\n",
    "# run test episodes\n",
    "ep_rets = []\n",
    "num_test_eps = 5\n",
    "frames = []\n",
    "test_env = wrappers.Monitor(test_env, \"./gym-results\", force=True)\n",
    "for j in range(num_test_eps):\n",
    "    o, d, ep_ret = test_env.reset(), False, 0\n",
    "    while not d:\n",
    "        a, logp = net.step(torch.as_tensor(o, dtype=torch.float32)) \n",
    "        o, r, d, _ = test_env.step(a) \n",
    "        ep_ret += r\n",
    "\n",
    "    ep_rets.append(ep_ret)\n",
    "test_env.close() # do not forget\n",
    "print(\"Average test reward: \", np.mean(ep_rets))\n",
    "\n",
    "# make the video\n",
    "video = io.open('./gym-results/openaigym.video.%s.video000000.mp4' % test_env.file_infix, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''\n",
    "    <video width=\"360\" height=\"auto\" alt=\"test\" controls><source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''\n",
    ".format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
